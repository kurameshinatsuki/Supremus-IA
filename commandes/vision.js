const { GoogleGenerativeAI } = require('@google/generative-ai');
const fs = require('fs');
const path = require('path');

// Initialisation des mod√®les
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const visionModel = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
const conversationModel = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

/**
 * Traite une image avec Google Vision
 */
async function analyzeImage(imageBuffer, imageMimeType) {
    try {
        // Convertir l'image en base64 pour l'API Gemini
        const base64Image = imageBuffer.toString('base64');
        
        const prompt = `
        Analyse cette image de mani√®re d√©taill√©e. D√©cris :
        1. Les √©l√©ments principaux visibles
        2. Les couleurs dominantes
        3. Le contexte ou l'ambiance
        4. Les textes √©ventuels
        5. Les d√©tails remarquables
        
        Sois pr√©cis et exhaustif dans ta description.
        `;

        const result = await visionModel.generateContent([
            prompt,
            {
                inlineData: {
                    data: base64Image,
                    mimeType: imageMimeType
                }
            }
        ]);

        const response = await result.response;
        return response.text();
    } catch (error) {
        console.error('‚ùå Erreur analyse image:', error);
        throw new Error('Impossible d\'analyser l\'image');
    }
}

/**
 * Combine l'analyse d'image avec le contexte de conversation
 */
async function generateImageResponse(imageAnalysis, userMessage, conversationContext) {
    try {
        const prompt = `
        CONTEXTE DE CONVERSATION:
        ${conversationContext}

        ANALYSE DE L'IMAGE:
        ${imageAnalysis}

        MESSAGE DE L'UTILISATEUR:
        ${userMessage}

        R√©ponds de mani√®re naturelle en int√©grant l'analyse de l'image dans la conversation.
        Sois pertinent avec le contexte et le message de l'utilisateur.
        `;

        const result = await conversationModel.generateContent(prompt);
        const response = await result.response;
        return response.text();
    } catch (error) {
        console.error('‚ùå Erreur g√©n√©ration r√©ponse image:', error);
        throw new Error('Erreur lors de la g√©n√©ration de la r√©ponse');
    }
}

async function execute(args, msg, sock) {
    try {
        // V√©rifier si le message contient une image
        const imageMessage = msg.message?.imageMessage;
        if (!imageMessage) {
            return "‚ùå Veuillez envoyer une image avec la commande /vision";
        }

        // T√©l√©charger l'image
        const stream = await downloadContentFromMessage(imageMessage, 'image');
        const chunks = [];
        for await (const chunk of stream) {
            chunks.push(chunk);
        }
        const imageBuffer = Buffer.concat(chunks);

        // Analyser l'image
        const analysis = await analyzeImage(imageBuffer, imageMessage.mimetype);

        // G√©n√©rer une r√©ponse contextuelle
        const response = await generateImageResponse(
            analysis, 
            "Que penses-tu de cette image ?",
            "L'utilisateur demande une analyse d'image."
        );

        return `üì∏ Analyse de l'image :\n${response}`;

    } catch (error) {
        console.error('‚ùå Erreur commande vision:', error);
        return "‚ùå Une erreur est survenue lors de l'analyse de l'image.";
    }
}

// Fonction utilitaire pour t√©l√©charger le contenu (√† importer depuis baileys)
const { downloadContentFromMessage } = require('@whiskeysockets/baileys');

module.exports = {
    name: 'vision',
    description: 'Analyse une image avec Google Vision',
    execute,
    analyzeImage, // Export pour utilisation dans d'autres modules
    generateImageResponse
};
