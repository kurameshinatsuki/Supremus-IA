const { GoogleGenerativeAI } = require('@google/generative-ai');
const { downloadContentFromMessage } = require('@whiskeysockets/baileys');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const visionModel = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

async function analyzeImage(imageBuffer, imageMimeType) {
    try {
        const base64Image = imageBuffer.toString('base64');
        
        const prompt = `**Analyse cette image de mani√®re d√©taill√©e et pr√©cise. D√©cris :**
       
        1. **EXTRAIT TEXTES VISIBLES** : D√©cris absolument tout le texte pr√©sent sur l'image (titre, sous-titre, description, etc)
        2. **√âL√âMENTS PRINCIPAUX** : Ce qui est visible au premier plan
        3. **CONTEXTE** : L'arri√®re-plan et l'environnement
        4. **COULEURS** : La palette de couleurs dominante
        5. **AMBIANCE** : L'atmosph√®re g√©n√©rale
        6. **D√âTAILS REMARQUABLES** : √âl√©ments sp√©cifiques int√©ressants
        7. **INTENTION/ACTION** : Ce qui semble se passer
        
        Sois objectif et factuel dans ton analyse.`;

        const result = await visionModel.generateContent([
            prompt,
            {
                inlineData: {
                    data: base64Image,
                    mimeType: imageMimeType
                }
            }
        ]);

        const response = await result.response;
        return response.text();
    } catch (error) {
        console.error('‚ùå Erreur analyse image:', error);
        return "Je n'ai pas pu analyser cette image.";
    }
}

async function execute(args, msg, sock) {
    try {
        const jid = msg.key.remoteJid;
        
        // V√©rifier si le message actuel contient une image
        let imageMessage = msg.message?.imageMessage;
        let quotedImage = null;

        // V√©rifier si c'est une r√©ponse √† une image
        if (!imageMessage && msg.message?.extendedTextMessage?.contextInfo?.quotedMessage) {
            quotedImage = msg.message.extendedTextMessage.contextInfo.quotedMessage.imageMessage;
        }

        const targetImage = imageMessage || quotedImage;

        if (!targetImage) {
            return `üëÅÔ∏è *Vision IA*\n\nPour analyser une image :\n‚Ä¢ üì∑ Envoyez une photo avec "/vision" comme l√©gende\n‚Ä¢ üîÑ Ou r√©pondez "/vision" √† une image existante\n\n*Je d√©crirai ce que je vois sur l'image*`;
        }

        // T√©l√©charger l'image
        console.log('üì• T√©l√©chargement image...');
        const stream = await downloadContentFromMessage(targetImage, 'image');
        const chunks = [];
        for await (const chunk of stream) {
            chunks.push(chunk);
        }
        const imageBuffer = Buffer.concat(chunks);

        // Analyser l'image
        console.log('üîç Analyse en cours...');
        const analysis = await analyzeImage(imageBuffer, targetImage.mimetype);
        
        return `üì∏ *Description de l'image :*\n\n${analysis}`;

    } catch (error) {
        console.error('‚ùå Erreur commande vision:', error);
        return "‚ùå D√©sol√©, je n'ai pas pu analyser l'image. Veuillez r√©essayer.";
    }
}

module.exports = {
    name: 'vision',
    description: 'Analyse une image avec Makima Supremus',
    execute
};
