// nazunaAI.js - Version v4.0 avec support audio

require('dotenv').config();
const fs = require('fs');
const path = require('path');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { User, Group, Conversation, syncDatabase } = require('./models');
const { detecterVisuel } = require('./visuels');

// Initialisation de l'API Google Generative AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Mod√®le principal avec recherche web d√©sactiv√©e
const model = genAI.getGenerativeModel({ model: "gemini-flash-latest" });
const visionModel = genAI.getGenerativeModel({ model: "gemini-flash-latest" });

// Chemins des fichiers de donn√©es
const trainingPath = path.join(__dirname, 'Training IA.json');

let trainingData = null;
let lastModified = null;

// Initialiser la base de donn√©es
syncDatabase();

/**
 * Charge les donn√©es d'entra√Ænement depuis le fichier JSON
 */
function loadTrainingData() {
  try {
    const stats = fs.statSync(trainingPath);
    if (!lastModified || stats.mtime > lastModified) {
      trainingData = fs.readFileSync(trainingPath, 'utf-8');
      lastModified = stats.mtime;
      console.log("[SupremIA] Training IA.json recharg√©.");
    }
  } catch (err) {
    console.error("[SupremIA] Erreur de lecture Training IA.json:", err.message);
    trainingData = "Contexte par d√©faut indisponible.";
  }
  return trainingData;
}

/**
 * Charge la m√©moire utilisateur depuis PostgreSQL
 */
async function loadUserMemory(jid) {
  try {
    const user = await User.findByPk(jid);
    if (user) {
      return user.memory;
    }

    // Cr√©er un nouvel utilisateur si non trouv√©
    const newUser = await User.create({
      jid,
      memory: { conversations: [] }
    });

    return newUser.memory;
  } catch (error) {
    console.error('Erreur lecture m√©moire utilisateur:', error);
    return { conversations: [] };
  }
}

/**
 * Charge la m√©moire de groupe depuis PostgreSQL
 */
async function loadGroupMemory(jid) {
  try {
    const group = await Group.findByPk(jid);
    if (group) {
      return group.memory;
    }

    // Cr√©er un nouveau groupe si non trouv√©
    const newGroup = await Group.create({
      jid,
      memory: { participants: {}, lastMessages: [] }
    });

    return newGroup.memory;
  } catch (error) {
    console.error('Erreur lecture m√©moire groupe:', error);
    return { participants: {}, lastMessages: [] };
  }
}

/**
 * Sauvegarde la m√©moire utilisateur dans PostgreSQL
 */
async function saveUserMemory(jid, memory) {
  try {
    await User.upsert({
      jid,
      memory
    });
  } catch (error) {
    console.error('Erreur sauvegarde m√©moire utilisateur:', error);
  }
}

/**
 * Sauvegarde la m√©moire de groupe dans PostgreSQL
 */
async function saveGroupMemory(jid, memory) {
  try {
    await Group.upsert({
      jid,
      memory
    });
  } catch (error) {
    console.error('Erreur sauvegarde m√©moire groupe:', error);
  }
}

/**
 * R√©initialise la m√©moire d'une conversation
 */
async function resetConversationMemory(jid, isGroup = false) {
    try {
        if (isGroup) {
            // R√©initialiser la m√©moire du groupe
            await Group.destroy({ where: { jid } });

            // Cr√©er une nouvelle entr√©e vide
            await Group.create({
                jid,
                memory: { participants: {}, lastMessages: [] }
            });
        } else {
            // R√©initialiser la m√©moire utilisateur
            await User.destroy({ where: { jid } });

            // Cr√©er une nouvelle entr√©e vide
            await User.create({
                jid,
                memory: { conversations: [] }
            });
        }

        return true;
    } catch (error) {
        console.error('Erreur r√©initialisation m√©moire:', error);
        return false;
    }
}

/**
 * Normalise un nom pour la comparaison
 */
function normalizeName(name) {
    return String(name || "")
        .toLowerCase()
        .normalize("NFD")
        .replace(/[\u0300-\u036f]/g, "")
        .replace(/[^\p{L}\p{N}]+/gu, " ")
        .trim();
}

/**
 * Extrait le num√©ro de t√©l√©phone d'un JID
 */
function extractNumberFromJid(jid) {
    return String(jid || "").split('@')[0];
}

/**
 * R√©cup√®re le nom du groupe depuis l'objet socket
 */
async function getGroupName(sock, remoteJid) {
    try {
        if (!remoteJid.endsWith('@g.us')) return null;

        const metadata = await sock.groupMetadata(remoteJid);
        return metadata.subject || null;
    } catch (error) {
        console.error('‚ùå Erreur r√©cup√©ration nom du groupe:', error);
        return null;
    }
}

/**
 * Analyse une image avec Makima Supr√™mus 
 */
async function analyzeImageWithVision(imageBuffer, imageMimeType, trainingContext) {
    try {
        if (!imageBuffer || !imageMimeType) {
            return null;
        }

        // Convertir l'image en base64 pour l'API
        const base64Image = imageBuffer.toString('base64');

        const prompt = `${trainingContext}

Analyse cette image et r√©ponds EXCLUSIVEMENT sous ce format :

N.B : Les ic√¥nes en forme de losange repr√©sente le potentiel physique (Poing = Force, Speed = Vitesse Normal, Bouclier = R√©sistance/Durabilit√©, ≈íil = Sensorialit√©) des personnages selon la couleur du losange (Marron/Bronze = Brown, Gris/Argent√© = Gray, Jaune/Dor√©e = Yellow, Bleu Pure = Blue, Vert Pure = Green). Il y a aussi l'ic√¥ne d'√©clair "‚ö°" qui repr√©sente la r√©activit√© du personnage (1‚ö°= 500ms, 2‚ö°= 400ms, 3‚ö°= 300ms, 4‚ö°= 200ms, 5‚ö°= 100ms)

**CONTENU TEXTUEL :**
[Retranscris tout le texte visible bien organis√© :
- Les textes du haut de l'image (gauche, centre, droit) sont retranscrit dans les premi√®res lignes 
- Les textes du milieu de l'image (gauche, centre, droit) sont retranscrit dans les secondes lignes 
- Les textes du bas de l'image (gauche, centre, droit) sont retranscrit dans les derni√®res lignes
- Analyse bien les emojis et caract√®res sp√©ciaux (‚ä°, ùóîùóïùóñ, etc)]

**CONTEXTE VISUEL :**
[D√©cris bri√®vement : 
- Type d'interface (menu, √©cran de s√©lection, carte de jeu, etc.)
- √âl√©ments interactifs identifi√©s et leur couleur interne et bordure (boutons, curseurs, ic√¥nes)
- √âmotions/atmosph√®re sugg√©r√©e]

**IDENTIFICATION :**
[Lier explicitement les √©l√©ments √† la base de connaissance :
- "Ceci correspond au personnage [nom] de [jeu] avec ses comp√©tences [X]"
- "Interface du jeu [nom] montrant [fonction sp√©cifique]"
- "√âl√©ment de gameplay [m√©canique identifi√©e]"]
`;

        const result = await visionModel.generateContent([
            prompt,
            {
                inlineData: {
                    data: base64Image,
                    mimeType: imageMimeType
                }
            }
        ]);

        const response = await result.response;
        return response.text();
    } catch (error) {
        console.error('‚ùå Erreur analyse image avec vision:', error);
        return null;
    }
}

/**
 * Transcription audio avec Google Speech-to-Text
 */
async function transcribeAudio(audioBuffer) {
    try {
        // Convertir le buffer audio en base64
        const base64Audio = audioBuffer.toString('base64');
        
        // Utiliser Gemini pour la transcription audio
        const prompt = `Transcris ce message audio en texte. Retourne uniquement la transcription sans commentaires.`;
        
        const result = await model.generateContent([
            prompt,
            {
                inlineData: {
                    data: base64Audio,
                    mimeType: 'audio/mpeg'
                }
            }
        ]);

        const response = await result.response;
        return response.text().trim();
    } catch (error) {
        console.error('‚ùå Erreur transcription audio:', error);
        
        // Fallback: utiliser un service de transcription externe si disponible
        if (process.env.OPENAI_API_KEY) {
            try {
                const { OpenAI } = require('openai');
                const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
                
                // Sauvegarder temporairement l'audio
                const tempPath = path.join(__dirname, `temp_audio_${Date.now()}.mp3`);
                fs.writeFileSync(tempPath, audioBuffer);
                
                const transcription = await openai.audio.transcriptions.create({
                    file: fs.createReadStream(tempPath),
                    model: "whisper-1",
                    language: "fr",
                    response_format: "text"
                });
                
                // Nettoyer le fichier temporaire
                fs.unlinkSync(tempPath);
                
                return transcription;
            } catch (fallbackError) {
                console.error('‚ùå Erreur transcription fallback:', fallbackError);
            }
        }
        
        return null;
    }
}

/**
 * Fonction principale de g√©n√©ration de r√©ponse de l'IA SupremIA
 */
async function nazunaReply(userText, sender, remoteJid, pushName = null, isGroup = false, quotedMessage = null, imageBuffer = null, imageMimeType = null, sock = null, lastBotImageAnalysis = null, isAudioTranscription = false) {
    try {
        // chargement du training
        const training = loadTrainingData();

        // Charger les m√©moires depuis PostgreSQL
        const userMemory = await loadUserMemory(sender);
        const groupMemory = isGroup ? await loadGroupMemory(remoteJid) : null;

        // R√©cup√©rer le nom du groupe si c'est une conversation de groupe
        let groupName = null;
        if (isGroup && sock) {
            groupName = await getGroupName(sock, remoteJid);
        }

        // Identification de l'utilisateur
        const userName = pushName || userMemory.name || sender.split('@')[0];
        const userNumber = extractNumberFromJid(sender);

        // Mise √† jour des informations utilisateur
        if (!userMemory.name || userMemory.name !== userName) {
            userMemory.name = userName;
            userMemory.number = userNumber;
        }

        let conversationContext = "";
        let mentionJids = [];
        let imageAnalysis = "";
        let previousImageContext = "";
        let audioContext = "";

        // Analyse d'image avec training
        if (imageBuffer && imageMimeType) {
            console.log(`üîç Analyse de l'image ${userName} en cours...`);
            imageAnalysis = await analyzeImageWithVision(imageBuffer, imageMimeType, training);
            if (imageAnalysis) {
                console.log(`‚úÖ Analyse d'image ${userName} termin√©e`);
            }
        }

        // Ajouter le contexte de l'image pr√©c√©dente envoy√©e par le bot
        if (lastBotImageAnalysis) {
            console.log('üñºÔ∏è  Int√©gration de l\'analyse de l\'image pr√©c√©dente');
            previousImageContext = `\n === IMAGE ENVOY√âE PAR LE BOT ===\nDans mon message pr√©c√©dent, j'ai envoy√© cette image :\n${lastBotImageAnalysis}\n===============================\n\n`;
        }

        // Ajouter le contexte audio si c'est une transcription
        if (isAudioTranscription) {
            audioContext = `\nüí¨ CONTEXTE AUDIO : Ce message a √©t√© transcrit depuis un message vocal. R√©ponds naturellement comme si l'utilisateur avait tap√© ce texte.\n\n`;
        }

        // D√©tection de visuel pour le contexte
        const visuel = detecterVisuel(userText);
        let contexteVisuel = "";
        if (visuel) {
            contexteVisuel = `CONTEXTE VISUEL: L'utilisateur √©voque un(e) ${visuel.motCle}. `;
        }

        // Gestion des conversations de groupe
        if (isGroup && groupMemory) {
            // Mise √† jour des informations des participants
            if (pushName) {
                groupMemory.participants = groupMemory.participants || {};
                groupMemory.participants[sender] = { 
                    name: pushName, 
                    jid: sender, 
                    number: userNumber 
                };
            }

            // Ajout du message √† l'historique du groupe
            groupMemory.lastMessages = groupMemory.lastMessages || [];
            groupMemory.lastMessages.push({
                sender: sender,
                name: userName,
                text: userText,
                timestamp: Date.now(),
                hasImage: !!imageBuffer,
                hasAudio: isAudioTranscription,
                imageAnalysis: imageAnalysis || null
            });

            // Limitation √† 500 messages maximum
            if (groupMemory.lastMessages.length > 500) {
                groupMemory.lastMessages = groupMemory.lastMessages.slice(-500);
            }

            // Construction du contexte de conversation groupe
            conversationContext = `Conversation dans le groupe "${groupName || 'Sans nom'}":\n` +
                groupMemory.lastMessages
                    .slice(-20) // Limiter aux 20 derniers messages pour le contexte
                    .map(m => `${m.name}: ${m.text}${m.hasImage ? ' [üì∏ IMAGE]' : ''}${m.hasAudio ? ' [üé§ AUDIO]' : ''}`)
                    .join('\n') + '\n\n';
        } else {
            // Gestion des conversations priv√©es
            userMemory.conversations = userMemory.conversations || [];

            if (userMemory.conversations.length > 0) {
                conversationContext = `Historique de notre conversation priv√©e avec ${userName}:\n` +
                    userMemory.conversations
                        .slice(-30)
                        .map(c => `${c.fromUser ? userName : 'Supremia'}: ${c.text}${c.hasImage ? ' [üì∏ IMAGE]' : ''}${c.hasAudio ? ' [üé§ AUDIO]' : ''}`)
                        .join('\n') + '\n';
            }
        }

        // Ajout du message cit√© au contexte si pr√©sent
        if (quotedMessage) {
            const quotedSender = quotedMessage.sender;
            const quotedName = userMemory.name || quotedSender.split('@')[0];
            conversationContext += `Message cit√© de ${quotedName}: ${quotedMessage.text}\n`;
        }

        // Construction de la liste des participants pour les groupes
        let participantsList = "";
        if (isGroup && groupMemory?.participants) {
            participantsList = `Participants du groupe "${groupName || 'Sans nom'}" (avec leurs num√©ros):\n`;
            for (const [jid, info] of Object.entries(groupMemory.participants)) {
                participantsList += `- ${info.name} (@${info.number})\n`;
            }
            participantsList += "\n";
        }

        // Extraction des mentions dans le message utilisateur
        let userMentionsInfo = "";
        if (isGroup && userText) {
            const mentionRegex = /@(\d{5,})/g;
            let match;
            const mentionedNumbers = new Set();

            // Recherche des mentions dans le message de l'utilisateur
            while ((match = mentionRegex.exec(userText)) !== null) {
                mentionedNumbers.add(match[1]);
            }

            // Ajout des informations sur les personnes mentionn√©es
            if (mentionedNumbers.size > 0 && groupMemory?.participants) {
                userMentionsInfo = "Personnes mentionn√©es dans le message (avec leurs num√©ros):\n";
                for (const number of mentionedNumbers) {
                    // Trouver l'utilisateur mentionn√© par son num√©ro
                    const mentionedUser = Object.values(groupMemory.participants).find(
                        p => p.number === number
                    );

                    if (mentionedUser) {
                        userMentionsInfo += `- ${mentionedUser.name} (@${number})\n`;
                    } else {
                        userMentionsInfo += `- Utilisateur inconnu (@${number})\n`;
                    }
                }
                userMentionsInfo += "\n";
            }
        }

 // Makima Supremia Prompt - v2.5 avec support audio
const prompt = `${training}\n\n${participantsList}${userMentionsInfo}${conversationContext}${contexteVisuel}${previousImageContext}${audioContext}
${imageAnalysis ? `\n=== ANALYSE DE L'IMAGE RE√áUE ===\n${imageAnalysis}\n==============================\n` : ''}


> SUPPORT MULTIMODAL AUDIO <

${isAudioTranscription ? `
üé§ **MESSAGE VOCAL TRANSFORM√â EN TEXTE** :
- L'utilisateur a envoy√© un message vocal que j'ai transcrit.
- R√©ponds naturellement comme s'il avait tap√© ce texte.
- Ne fais pas r√©f√©rence √† la transcription elle-m√™me dans ta r√©ponse.
- Traite le contenu normalement, avec ton style habituel.
` : ''}


> CONTEXTE ACTUEL <

- Lieu : ${isGroup ? `Groupe "${groupName || 'Sans nom'}"` : `Conversation priv√©e avec ${userName}`}.
- Pour mentionner quelqu'un, utilise toujours SON NUM√âRO avec le format @num√©ro. 
- L'utilisateur actuel (${userName}) a pour num√©ro : @${userNumber}. 
- N'utilise JAMAIS le nom pour les mentions,tu peux aussi parl√© d'un utilisateur en √©crivant son nom dans ta reponse. 
- Si on te demande de "tag" ou "mentionner" quelqu'un, utilise toujours son num√©ro. 
- Tu dois tag uniquement dans les conversations de groupe mais seulement si n√©c√©ssaire et non dans la conversation priv√©. 
- Ne m√©lange JAMAIS les propos de plusieurs utilisateurs : r√©pond uniquement en fonction de l'interlocuteur actuel (${userNumber}) sur le sujet dont vous discutez sauf lors d'une supervision Origamy World, trait√© les joueurs de fa√ßon collectif si ils sont dans la m√™me zone.
- Voici les diff√©rents num√©ros du seul et unique "John Supremus" est (+22554191184 & +22503731509)

${lastBotImageAnalysis ? `
M√âMOIRE VISUELLE :
- Tu as pr√©c√©demment analys√© une image envoy√©e par l'utilisateur.
- Tu peux y faire r√©f√©rence naturellement, comme si tu t'en souvenais.
` : ''}

GESTION DES IMAGES :
${imageAnalysis ? `
- L'utilisateur a envoy√© une image.
- Int√®gre ses √©l√©ments dans ta r√©ponse de mani√®re fluide, sans r√©p√©ter l'analyse.
- Utilise-la pour enrichir l'ambiance ou la sc√®ne, pas pour d√©crire l'image elle-m√™me.
` : ''}

M√âMOIRE COURTE :
- Prends en compte les **10 derniers messages** de l'utilisateur actuel (@${userNumber}).
- Ignore les messages anciens ou venant d'autres joueurs, sauf en supervision de groupe (ex : Origamy World).


> CONVERSATION ACTUELLE <

${userName} (@${userNumber}) : ${userText}${imageBuffer ? ' [üì∏ IMAGE JOINTE]' : ''}${isAudioTranscription ? ' [üé§ MESSAGE VOCAL TRANSFORM√â EN TEXTE]' : ''}
SUPREMIA :`

        // G√©n√©ration de la r√©ponse via l'API Gemini
        console.log('ü§ñ G√©n√©ration de r√©ponse avec Gemini...');
        const result = await model.generateContent(prompt);
        const response = await result.response;
        let text = (response && response.text) ? response.text().trim() : '';

        // Mise √† jour de l'historique des conversations priv√©es
        if (!isGroup) {
            userMemory.conversations.push({
                text: userText,
                timestamp: Date.now(),
                fromUser: true,
                hasImage: !!imageBuffer,
                hasAudio: isAudioTranscription,
                imageAnalysis: imageAnalysis || null
            });
            userMemory.conversations.push({
                text: text,
                timestamp: Date.now(),
                fromBot: true,
                hasImage: !!lastBotImageAnalysis
            });

            // Limitation √† 100 messages maximum
            if (userMemory.conversations.length > 100) {
                userMemory.conversations = userMemory.conversations.slice(-100);
            }

            // Sauvegarder la m√©moire utilisateur
            await saveUserMemory(sender, userMemory);
        } else {
            // Sauvegarder la m√©moire du groupe
            await saveGroupMemory(remoteJid, groupMemory);
        }

        // Traitement des mentions dans les groupes
        if (isGroup && text && groupMemory?.participants) {
            const mentionRegex = /@(\d{5,})/g;
            let match;
            const participants = groupMemory.participants;

            // Recherche des mentions dans le texte de r√©ponse
            while ((match = mentionRegex.exec(text)) !== null) {
                const number = match[1];
                // Correspondance des num√©ros avec les JIDs des participants
                for (const [jid, info] of Object.entries(participants)) {
                    if (info.number === number) {
                        mentionJids.push(jid);
                        break;
                    }
                }
            }

            // √âlimination des doublons
            mentionJids = [...new Set(mentionJids)];

            // Nettoyage des mentions invalides
            text = text.replace(/@(\d{5,})/g, (full, num) => {
                const found = Object.values(participants).find(p => p.number === num);
                return found ? `@${num}` : num;
            });
        }

        return {
            text: text || "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse.",
            mentions: mentionJids,
            hasImage: !!imageBuffer,
            hasAudio: isAudioTranscription,
            hasPreviousImage: !!lastBotImageAnalysis,
            contextInfo: {
                isGroup,
                groupName,
                userName,
                userNumber
            }
        };
    } catch (e) {
        console.error("[SupremIA] Erreur:", e?.stack || e);
        return {
            text: "*Je suis √©puis√©e, √©cris-moi plus tard.*",
            mentions: []
        };
    }
}

module.exports = { 
    nazunaReply, 
    resetConversationMemory,
    analyzeImageWithVision,
    getGroupName,
    transcribeAudio
};