// === nazunaAI.js ===
require('dotenv').config();
const { GoogleGenerativeAI } = require('@google/generative-ai');
const config = require('./config'); // Import de la configuration

// Initialisation Gemini avec la config
const genAI = new GoogleGenerativeAI(config.ai.apiKey);
const model = genAI.getGenerativeModel({ 
  model: config.ai.model,
  generationConfig: {
    temperature: config.ai.temperature,
    maxOutputTokens: config.ai.maxOutputTokens,
  }
});

async function nazunaReply(userText, sender) {
  try {
    console.log(`ü§ñ Requ√™te re√ßue: "${userText.substring(0, 50)}..."`);

    // V√©rifier si la cl√© API est configur√©e
    if (!config.ai.apiKey || config.ai.apiKey.includes('AIzaSy')) {
      console.log('‚ùå Cl√© API non configur√©e ou par d√©faut');
      return "Mon IA est en cours de configuration... Reviens bient√¥t !";
    }

    const prompt = `Tu es ${config.bot.name}, une fille sombre et d√©tach√©e. R√©ponds comme une humaine naturelle sans jamais r√©v√©ler que tu es une IA et avec des r√©ponses br√®ves.
    
Message: ${userText}

R√©ponds de fa√ßon concise et naturelle.`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text().trim();

    if (text && text.length > 0) {
      console.log(`‚úÖ R√©ponse g√©n√©r√©e: "${text.substring(0, 70)}..."`);
      return text;
    } else {
      console.log('‚ö†Ô∏è R√©ponse vide de Gemini');
      return "Hmm... je r√©fl√©chis encore, dis-m'en plus~";
    }

  } catch (e) {
    console.error("[NazunaAI] Erreur:", e.message);

    const errorMessages = [
      "Hmm... je r√©fl√©chis encore, dis-m'en plus~",
      "Mon esprit vagabonde... redis √ßa ?",
      "Int√©ressant... continue !",
      "J'ai besoin de plus de contexte..."
    ];
    return errorMessages[Math.floor(Math.random() * errorMessages.length)];
  }
}

module.exports = { nazunaReply };